{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import helper_functions\n",
    "\n",
    "import spacy\n",
    "import serrant\n",
    "\n",
    "import re, json\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from nltk import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "USE_L1_LEVEL = False\n",
    "\n",
    "#load the model\n",
    "model_id = '/mnt/data/samdavid/projects/projects/dissertation/training_code/t5_finetune/' + 'cowsl2h_MT5_model'\n",
    "tokenizer = MT5Tokenizer.from_pretrained('google/mt5-base')\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_id).to(torch_device)\n",
    "\n",
    "nlp = spacy.load('es')\n",
    "annotator = serrant.load('en', nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_text,num_return_sequences):\n",
    "    batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5, do_sample=True)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gec(input_essay):\n",
    "\n",
    "    # create temp directory\n",
    "    try:\n",
    "        os.mkdir('tmp')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    orig_lines = []\n",
    "\n",
    "    for sent in sent_tokenize(input_essay):\n",
    "        # remove original tokenize spaces\n",
    "        sent = sent.strip()\n",
    "        doc = nlp.tokenizer(sent)\n",
    "        tokens = [token.text for token in doc]\n",
    "        # whether to put utterances in the same line or not\n",
    "        orig_lines.append(\" \".join(tokens))\n",
    "\n",
    "    # predict\n",
    "    num_return_sequences = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for sent in orig_lines:\n",
    "        sent_results = correct_grammar(sent, num_return_sequences)\n",
    "        results.extend(sent_results)\n",
    "        \n",
    "    print(results)\n",
    "\n",
    "    cor_lines = results\n",
    "    #for generated_sequence_idx, generated_sequence in enumerate(results):\n",
    "    #    # Decode text\n",
    "    #    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "    #    cor_lines.append(text)\n",
    "\n",
    "    # # generate corrections\n",
    "    edits = []\n",
    "    #add sent index to keep track of which sent the edits belong to\n",
    "    sent_index = 0\n",
    "    for orig, cor in zip(orig_lines, cor_lines):\n",
    "        orig_parse = annotator.parse(orig)\n",
    "        cor_parse = annotator.parse(cor)\n",
    "        print(cor_parse)\n",
    "        sent_edits = annotator.annotate(orig_parse, cor_parse)\n",
    "        edits.append((orig_parse, cor_parse, sent_edits, sent_index))\n",
    "        sent_index += 1\n",
    "\n",
    "    return edits, cor_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_errors(edit_list):\n",
    "    initial_target_list = [\"R:VERB:SVA\", 'R:PREP:WC', 'M:PRON', 'R:VERB:TENSE', 'R:NOUN:NUM', 'R:VERB:FORM', 'M:PREP', 'U:PREP', 'M:VERB']\n",
    "\n",
    "    num_errors = 0\n",
    "    out_edits = []\n",
    "\n",
    "### Printing errors for testing\n",
    "    errors_tagged = []\n",
    "    for sent in edit_list:\n",
    "        for edit_item in sent[2]:\n",
    "            errors_tagged.append(edit_item.type)\n",
    "\n",
    "    print(f\"Number of errors tagged {len(errors_tagged)}\")\n",
    "    print(errors_tagged)\n",
    "### End printing errors for testing\n",
    "\n",
    "    #max errors presented per dialogue == 3 (this is something we need to test)\n",
    "    for target in initial_target_list:\n",
    "        for sent in edit_list:\n",
    "            for edit_item in sent[2]:\n",
    "                edit_type = edit_item.type\n",
    "                if num_errors >= 3:\n",
    "                    break\n",
    "                if target in edit_type:\n",
    "                    #limit number of corrections for specific target to 1 per sentence\n",
    "                    orig_sent = sent[0]\n",
    "                    cor_sent = sent[1]\n",
    "                    sent_index = sent[3]\n",
    "                    out_edits.append((orig_sent, cor_sent, edit_item, target, sent_index))\n",
    "                    num_errors += 1\n",
    "                    break\n",
    "        if num_errors >= 3:\n",
    "            break\n",
    "\n",
    "    return out_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback(edit_list, l1, level):\n",
    "    errors_to_present = rank_errors(edit_list)\n",
    "    print(errors_to_present)\n",
    "    out_dict = {}\n",
    "    error_count = 0\n",
    "    \n",
    "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "    #level = 1\n",
    "    #l1 = 'english'\n",
    "    #original = \"Yo estoy feliz con mi mismo.\"\n",
    "\n",
    "    prompt2 = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are the teacher of a Spanish {level} course. You are writing corrections for a student whose native language is {l1}. You want to provide your students with feedback about mistakes in their writing. Given an original sentence written by a student, and a corrected version of the sentence written by you, explain to the student why you made the corrections you made. Don't change either sentence. Just explain the differences between them in terms of grammar in a way a student can understand.\"),\n",
    "        (\"user\", \"Original sentence: {original}\\nCorrected Sentence: {corrected}\")\n",
    "    ])\n",
    "\n",
    "    chain2 = (    prompt2\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    "             )\n",
    "\n",
    "    \n",
    "    for error in errors_to_present:\n",
    "        #unpack edit tuple\n",
    "        orig_sentence = error[0]\n",
    "        cor_sentence = error[1]\n",
    "        edit_item = error[2]\n",
    "        target = error[3]\n",
    "\n",
    "        if \"R:VERB:SVA\" in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"In this sentence '{orig_sent}' you made a mistake on the verb '{orig_tok}'. The correct verb form here is '{cor_tok}'. Remember to make your verbs agree with their subjects. Here's the corrected sentence: {cor_sent}\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str, cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"In this sentence '{orig_sent}' you made a mistake on the verb '{orig_tok}'. What verb form should you have used?\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str)\n",
    "            response_1_correct = \"Good job. Remember to make your verbs agree with their subjects.\"\n",
    "            response_1_incorrect = \"Not quite. Think about subject-verb agreement. How should your verb be changed to agree with the subject '{subject}'?\".format(subject=helper_functions.get_subject_phrase(orig_sentence))\n",
    "            response_2_correct = \"Good job. Remember to make your verbs agree with their subjects.\"\n",
    "            response_2_incorrect = \"Good try, but not quite. It's tricky, I know. The correct verb form here is '{cor_tok}'. Remember to make your verbs agree with their subjects. Here's the corrected sentence: {cor_sent}\".format(cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif \"R:PREP:WC\" in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"In this sentence '{orig_sent}' you made a mistake on the preposition '{orig_tok}', which doesn't sound natural. I'd recommend using '{cor_tok}' in this case. Here's the corrected sentence: {cor_sent}.\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str, cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "            \n",
    "            line_1 = \"In this sentence '{orig_sent}' you made a mistake on the preposition '{orig_tok}', which doesn't sound natural. What other preposition should you have used?\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str)\n",
    "            response_1_correct = \"Great! '{cor_tok}' definitely sounds better in this sentence.\".format(cor_tok=edit_item.c_str)\n",
    "            response_1_incorrect = \"That still seems a bit off. Think about common prepositions and what might sound better here. Try one more time.\"\n",
    "            response_2_correct = \"Good job. That's the preposition I'd recommend. Sounds better, right?\"\n",
    "            response_2_incorrect = \"I still don't think that's right. I'd recommend using '{cor_tok}' in this case. Here's the corrected sentence: {cor_sent}.\".format(cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif 'M:PRON' in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"You seem to be missing a pronoun in the sentence '{orig_sent}'. You should probably include '{cor_tok}' to make the sentence grammatical. Here's the corrected sentence: {cor_sent}\".format(orig_sent=orig_sentence.text, cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"You seem to be missing a pronoun in the sentence '{orig_sent}'. How could you improve this sentence by adding a pronoun?\".format(orig_sent=orig_sentence.text)\n",
    "            response_1_correct = \"Yep, that's right. '{cor_tok}' is needed to make the sentence grammatical.\".format(cor_tok=edit_item.c_str)\n",
    "            response_1_incorrect = \"Not quite. Remember, prepositions and many verbs need an object like 'it' or 'him'. Try again.\"\n",
    "            response_2_correct = \"Great! '{cor_tok}' is what the sentence was missing.\".format(cor_tok=edit_item.c_str)\n",
    "            response_2_incorrect = \"You're still missing something. You should probably include '{cor_tok}' to make the sentence grammatical. Here's the corrected sentence: {cor_sent}\".format(cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif 'R:VERB:TENSE' in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"The verb tense you used in '{orig_sent}' isn't quite right. You should probably use '{cor_tok}' instead of '{orig_tok}' here. Here's the corrected sentence: {cor_sent}.\".format(cor_tok=edit_item.c_str, orig_tok=edit_item.o_str, cor_sent=cor_sentence.text, orig_sent=orig_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"The verb tense you used in '{orig_sent}' isn't quite right. What would be a better tense of the verb '{lemma}' to use here?\".format(orig_sent=orig_sentence.text, lemma=helper_functions.get_lemma(edit_item))\n",
    "            response_1_correct = \"You got it! '{cor_tok}' makes more sense in this context. Remeber, make your verb tenses consistent.\".format(cor_tok=edit_item.c_str)\n",
    "            response_1_incorrect = \"You're still a little off. Remeber, you need to make your verb tenses consistent within and between sentences. Give it another try.\"\n",
    "            response_2_correct = \"Nice! That's exactly what you need. '{cor_tok}' is the right tense for this sentence.\".format(cor_tok=edit_item.c_str)\n",
    "            response_2_incorrect = \"Not quite. You should probably use '{cor_tok}' instead of '{orig_tok}' here. Here's the corrected sentence: {cor_sent}.\".format(cor_tok=edit_item.c_str, orig_tok=edit_item.o_str, cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif 'R:NOUN:NUM' in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"In '{orig_sent}' you used a {orig_number} noun where you should have used a {cor_number} noun. In this context, the noun {orig_tok} should be the {cor_number} noun {cor_tok}. Here's the corrected sentence: {cor_sent}.\".format(orig_sent=orig_sentence.text, orig_number=helper_functions.get_number(edit_item, 'orig'), cor_number=helper_functions.get_number(edit_item, 'cor'), cor_tok=edit_item.c_str, orig_tok=edit_item.o_str, cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"In '{orig_sent}' you used a {orig_number} noun where you should have used a {cor_number} noun. Can you spot the mistake? What would be the right noun form to use?\".format(orig_sent=orig_sentence.text, orig_number=helper_functions.get_number(edit_item, 'orig'), cor_number=helper_functions.get_number(edit_item, 'cor'))\n",
    "            response_1_correct = \"That's right! '{cor_tok}' should be plural in this context.\".format(cor_tok=edit_item.c_str)\n",
    "            response_1_incorrect = \"That's not the correction I was looking for. Remeber that when you're talking about things 'in general' (like movies or books) you often want to use a plural. Try one more time.\"\n",
    "            response_2_correct = \"Great! '{cor_tok}' should be plural in this context.\".format(cor_tok=edit_item.c_str)\n",
    "            response_2_incorrect = \"That's not the error I was thinking about. In this context, the noun {orig_tok} should be the {cor_number} noun {cor_tok}. Here's the corrected sentence: {cor_sent}.\".format(cor_tok=edit_item.c_str, cor_number=helper_functions.get_number(edit_item, 'cor'), orig_tok=edit_item.o_str, cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif 'R:VERB:FORM' in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"In '{orig_sent}' there's an issue with the form of the verb '{orig_tok}'. In this context, the verb '{orig_lemma}' should be the {cor_form} '{cor_tok}'. Here's the corrected sentence: {cor_sent}.\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str, cor_tok=edit_item.c_str, cor_form=helper_functions.get_verb_form(edit_item, 'cor'), orig_lemma=helper_functions.get_lemma(edit_item), cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"In '{orig_sent}' there's an issue with the form of the verb '{orig_tok}'. What would be a better form of this verb to use?\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str)\n",
    "            response_1_correct = \"Exactly! In this sentence you should have used the {cor_form} form '{cor_tok}' instead of the {orig_form} form '{orig_tok}'.\".format(cor_tok=edit_item.c_str, orig_tok=edit_item.o_str, cor_form=helper_functions.get_verb_form(edit_item, 'cor'), orig_form=helper_functions.get_verb_form(edit_item, 'orig'))\n",
    "            response_1_incorrect = \"Good try, but that's still a bit off. You should have used {cor_form} form of the verb '{orig_lemma}'. What would that form be?\".format(cor_form=helper_functions.get_verb_form(edit_item, 'cor'), orig_lemma=helper_functions.get_lemma(edit_item))\n",
    "            response_2_correct = \"Good job! That's the correct form I was looking for. Remember in English, we usually use participles after helping verbs like 'have' and 'is'.\"\n",
    "            response_2_incorrect = \"That's still not quite right. In this context, the verb '{orig_lemma}' should be the {cor_form} '{cor_tok}'. Here's the corrected sentence: {cor_sent}.\".format(cor_tok=edit_item.c_str, cor_form=helper_functions.get_verb_form(edit_item, 'cor'), orig_lemma=helper_functions.get_lemma(edit_item), cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif 'M:PREP' in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"You seem to be missing a preposition in the sentence '{orig_sent}.' You should probably add '{cor_tok}' to make the sentence sound more natural. Here's the corrected sentence: {cor_sent}\".format(orig_sent=orig_sentence.text, cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"You seem to be missing a preposition in the sentence '{orig_sent}' How could you improve the sentence by adding a prepostion?\".format(orig_sent=orig_sentence.text)\n",
    "            response_1_correct = \"Yep, that's right. '{cor_tok}' is needed to make the sentence grammatical.\".format(cor_tok=edit_item.c_str)\n",
    "            response_1_incorrect = \"Not quite. Remember, a lot of fixed expressions require prepositions, like 'think about' or 'because of'. Try adding a preposition to the sentence one more time.\"\n",
    "            response_2_correct = \"Great! '{cor_tok}' is what the sentence is missing.\".format(cor_tok=edit_item.c_str)\n",
    "            response_2_incorrect = \"You're still missing something. You should probably add '{cor_tok}' to make the sentence sound more natural. Here's the corrected sentence: {cor_sent}\".format(cor_tok=edit_item.c_str, cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "        elif 'U:PREP' in target:\n",
    "            #Don't know if I should include the full sentence\n",
    "            response_short = \"You seem to have included an unneeded preposition in the sentence '{orig_sent}'. In this context, you should drop the {orig_tok} before {next_tok}. Here's the corrected sentence: {cor_sent}\".format(orig_sent=orig_sentence.text, orig_tok=edit_item.o_str, next_tok=helper_functions.get_next_tok(edit_item, orig_sentence), cor_sent=cor_sentence.text)\n",
    "            llm_explanation = chain2.invoke({\"l1\": l1, \"level\": level, \"original\": orig_sentence, \"corrected\": cor_sentence})\n",
    "\n",
    "            line_1 = \"You seem to have included an unneeded preposition in the sentence '{orig_sent}'. How could you fix the sentence by removing a prepostion?\".format(orig_sent=orig_sentence.text)\n",
    "            response_1_correct = \"That's right. '{orig_tok}' isn't needed in this context, and it makes the sentence sound awkwark.\".format(orig_tok=edit_item.o_str)\n",
    "            response_1_incorrect = \"That's not what I was thinking of. Often, people add extra prepostions like to, of and by. Try rewording your sentence again.\"\n",
    "            response_2_correct = \"Excellent. Dropping the '{orig_tok}' definitely makes this sentence sound better.\".format(orig_tok=edit_item.o_str)\n",
    "            response_2_incorrect = \"That still sounds a little off. In this context, you should drop the {orig_tok} before {next_tok}. Here's the corrected sentence: {cor_sent}\".format(orig_tok=edit_item.o_str, next_tok=helper_functions.get_next_tok(edit_item, orig_sentence), cor_sent=cor_sentence.text)\n",
    "\n",
    "            out_dict['edit_' + str(error_count)] = {\"response_short\": response_short, \"llm_explanation\": llm_explanation, \"line_1\":line_1, \"response_1\":{'correct':response_1_correct, 'incorrect':response_1_incorrect}, 'response_2':{'correct':response_2_correct, 'incorrect':response_2_incorrect}}\n",
    "            error_count += 1\n",
    "\n",
    "\n",
    "    json_out = json.dumps(out_dict)\n",
    "\n",
    "    return json_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your course level:1\n",
      "Enter your native language (english|spanish|mandarin|other):english\n",
      "Write an essay in Spanish: Normalmente por vacaciones de Acción de Gracias, yo voy a la casa de mi tía en *STATE* para tres días. Mi papa tiene seis hermanos, así que yo tengo una familia grande. Yo vivo en *STATE* y mi familia vive lejos de me, entonces no los veo a menudo. El Día de Acción de Gracias es mi día de fiesta preferido porque yo puedo ver mi familia. Todo la familia va a la casa de mi tía. Este año no puedo ir a la casa de mi tía porque el coronavirus. Estuve muy triste, pero así que visito mi hermana menor en *CITY* con mi novio. Nosotros vimos tres películas, comimos mucho buena comida, y caminamos en la ciudad y el parque centro. Estuvimos muy feliz. ¡CITY is muy interesante! Tiene mucha gente differente. El Día de Acción de Gracias, quedamos en el apartamento pequeño de mi hermana. Solo teníamos una estufa y tres quemadores y tres personas, ¡pero hicimos un festín! Fue divertido y delicioso. Hicimos los panecillos, los boniatos horneados, el puré de papas, el pollo al horno, las tartes de champiñón, la salsa de arándano, y el relleno. ¡Que rico! Comimos la sobras para mucho días. También llamamos nos mama y papa y hablamos con ellos. Aunque ellos estan en *CITY*, sentí estamos cerca de nosotros. Aunque no puedo ir a la casa de mi tía con mi familia grande, este año estuve muy contento con mi familia pequeña. Todavía El Día de Acción de Gracias es mi día de fiesta preferido.\n",
      "['Normalmente por vacaciones de Acción de Gracias, voy a la casa de mi tía en *STATE * por tres días.', 'Mi papá tiene seis hermanos, así que tengo una familia grande.', 'Yo vivo en *STATE * y mi familia vive lejos de mí, entonces no los veo a menudo.', 'El Día de Acción de Gracias es mi día de fiesta preferido porque puedo ver a mi familia.', 'Todo la familia va a la casa de mi tía.', 'Este año no puedo ir a la casa de mi tía porque el coronavirus.', 'Estuve muy triste, pero así que visito a mi hermana menor en *CITY * con mi novio.', 'Vimos tres películas, comimos mucha buena comida y caminamos en la ciudad y el parque centro.', 'Estuvimos muy felices.', '¡CITY es muy interesante!', 'Tiene mucha gente diferente.', 'El Día de Acción de Gracias, quedamos en el apartamento pequeño de mi hermana.', 'Solo teníamos una estufa y tres quemadores y tres personas, ¡pero hicimos un festín!', 'Fue divertido y delicioso.', 'Hicimos panecillos, los boniatos horneados, el puré de papas, el pollo al horno, las tartes de champiñón, la salsa de arándano y el relleno.', '¡Qué rico!', 'Comimos la sobra para muchos días.', 'También llamamos a nos mamá y papa y hablamos con ellos.', 'Aunque ellos están en *CITY *, sentí que estamos cerca de nosotros.', 'Aunque no puedo ir a la casa de mi tía con mi familia grande, este año estuve muy contento con mi familia pequeña.', 'Todavía el Día de Acción de Gracias es mi día de fiesta preferido.']\n",
      "Normalmente por vacaciones de Acción de Gracias, voy a la casa de mi tía en *STATE * por tres días. \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'PROPN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m edits, cor_lines \u001b[38;5;241m=\u001b[39m \u001b[43mgec\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_essay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m edits_to_present \u001b[38;5;241m=\u001b[39m rank_errors(edits)\n\u001b[1;32m     16\u001b[0m feedback \u001b[38;5;241m=\u001b[39m generate_feedback(edits_to_present, l1, level)\n",
      "Cell \u001b[0;32mIn[28], line 44\u001b[0m, in \u001b[0;36mgec\u001b[0;34m(input_essay)\u001b[0m\n\u001b[1;32m     42\u001b[0m cor_parse \u001b[38;5;241m=\u001b[39m annotator\u001b[38;5;241m.\u001b[39mparse(cor)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(cor_parse)\n\u001b[0;32m---> 44\u001b[0m sent_edits \u001b[38;5;241m=\u001b[39m \u001b[43mannotator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_parse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcor_parse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m edits\u001b[38;5;241m.\u001b[39mappend((orig_parse, cor_parse, sent_edits, sent_index))\n\u001b[1;32m     46\u001b[0m sent_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/mnt/data/samdavid/utils/serrant/serrant/annotator.py:105\u001b[0m, in \u001b[0;36mAnnotator.annotate\u001b[0;34m(self, orig, cor, lev, merging, annotator)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mannotate\u001b[39m(\u001b[38;5;28mself\u001b[39m, orig, cor, lev\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, merging\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrules\u001b[39m\u001b[38;5;124m\"\u001b[39m, annotator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     errant_edits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrant_annotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     sercl_edits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyntax_annotate(orig, cor, lev, merging)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errant_edits) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(sercl_edits)\n",
      "File \u001b[0;32m/mnt/data/samdavid/utils/serrant/serrant/annotator.py:83\u001b[0m, in \u001b[0;36mAnnotator.errant_annotate\u001b[0;34m(self, orig, cor, lev, merging)\u001b[0m\n\u001b[1;32m     81\u001b[0m edits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge(alignment, merging)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edit \u001b[38;5;129;01min\u001b[39;00m edits:\n\u001b[0;32m---> 83\u001b[0m     edit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify_by_errant\u001b[49m\u001b[43m(\u001b[49m\u001b[43medit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edits\n",
      "File \u001b[0;32m/mnt/data/samdavid/utils/serrant/serrant/annotator.py:67\u001b[0m, in \u001b[0;36mAnnotator.classify_by_errant\u001b[0;34m(self, edit)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_by_errant\u001b[39m(\u001b[38;5;28mself\u001b[39m, edit):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrant_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43medit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/samdavid/utils/serrant/serrant/en/classifier.py:111\u001b[0m, in \u001b[0;36mclassify\u001b[0;34m(edit)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Replacement\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 111\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[43mget_two_sided_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43medit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_toks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_toks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     edit\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m+\u001b[39mcat[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    113\u001b[0m     edit\u001b[38;5;241m.\u001b[39mcond \u001b[38;5;241m=\u001b[39m cat[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/mnt/data/samdavid/utils/serrant/serrant/en/classifier.py:165\u001b[0m, in \u001b[0;36mget_two_sided_type\u001b[0;34m(o_toks, c_toks)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_two_sided_type\u001b[39m(o_toks, c_toks):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Extract pos tags and parse info from the toks as lists\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     o_pos, o_dep \u001b[38;5;241m=\u001b[39m \u001b[43mget_edit_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo_toks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     c_pos, c_dep \u001b[38;5;241m=\u001b[39m get_edit_info(c_toks)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Orthography; i.e. whitespace and/or case errors.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/samdavid/utils/serrant/serrant/en/classifier.py:122\u001b[0m, in \u001b[0;36mget_edit_info\u001b[0;34m(toks)\u001b[0m\n\u001b[1;32m    120\u001b[0m dep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m toks:\n\u001b[0;32m--> 122\u001b[0m     pos\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpos_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtok\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag_\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    123\u001b[0m     dep\u001b[38;5;241m.\u001b[39mappend(tok\u001b[38;5;241m.\u001b[39mdep_)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pos, dep\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PROPN'"
     ]
    }
   ],
   "source": [
    "level = input(\"Enter your course level:\")\n",
    "l1 = input(\"Enter your native language (english|spanish|mandarin|other):\")\n",
    "\n",
    "original = ''\n",
    "\n",
    "while True:\n",
    "    original_essay = input(\"Write an essay in Spanish: \")\n",
    "    \n",
    "    if original == 'exit':\n",
    "        break\n",
    "        \n",
    "    edits, cor_lines = gec(original_essay)\n",
    "    \n",
    "    edits_to_present = rank_errors(edits)\n",
    "    \n",
    "    feedback = generate_feedback(edits_to_present, l1, level)\n",
    "    \n",
    "    corrected_essay = ' '.join(cor_lines)\n",
    "    \n",
    "    print(f\"Original: {original_essay}\")\n",
    "    print(f\"Corrected: {corrected_essay}\")\n",
    "\n",
    "    print(feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_serrant",
   "language": "python",
   "name": "torch_serrant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
